{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "outs = {}\n",
    "\n",
    "\n",
    "for filename in sorted([f for f in glob.glob(\"../output/*.json\") if \"test\" not in f]): \n",
    "    model_name = os.path.basename(filename).split(\".\")[0]\n",
    "    print(model_name)\n",
    "    with open(filename) as f:\n",
    "        outs[model_name] = json.load(f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bertin\n",
      "beto-cased-10000\n",
      "beto-cased-20000\n",
      "beto-cased-2500\n",
      "beto-cased-5000\n",
      "beto-cased\n",
      "beto-uncased-10000\n",
      "beto-uncased-20000\n",
      "beto-uncased-2500\n",
      "beto-uncased-5000\n",
      "beto-uncased\n",
      "checkpoint-46k\n",
      "checkpoint-62k\n",
      "checkpoint-87k\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-uncased\",\n",
    "    #\"beto-uncased-2500\",\n",
    "    #\"beto-uncased-5000\",\n",
    "    #\"beto-uncased-10000\",\n",
    "    #\"beto-uncased-20000\",\n",
    "    \"checkpoint-46k\",\n",
    "    \"checkpoint-62k\",\n",
    "    \"checkpoint-87k\",\n",
    "    \"beto-cased\",\n",
    "    #\"beto-cased-2500\",\n",
    "    #\"beto-cased-5000\",\n",
    "    #\"beto-cased-10000\",\n",
    "    #\"beto-cased-20000\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "old_score_cols = [\"context_hate mean_f1\", \"hate hateful_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "score_cols = [\"context_hate mean_f1\", \"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "score_without_chate_cols = [\"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"old_score\"] = df_mean.loc[order, old_score_cols].mean(axis=1)\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "df.loc[order, \"score2\"] = df_mean.loc[order, score_without_chate_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c and \"score\" not in c] + [\"score\", \"score2\", \"old_score\", ]\n",
    "\n",
    "df.loc[order, columns]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               context_hate mean_f1 context_hate hate_f1  hate hateful_f1  \\\n",
       "model                                                                       \n",
       "bertin              0.5559 +- 0.002      0.6713 +- 0.002  0.7444 +- 0.004   \n",
       "beto-uncased        0.5895 +- 0.006      0.6907 +- 0.005  0.7344 +- 0.007   \n",
       "checkpoint-46k      0.5255 +- 0.006      0.6503 +- 0.006  0.7534 +- 0.003   \n",
       "checkpoint-62k      0.5175 +- 0.021      0.6470 +- 0.018  0.7502 +- 0.004   \n",
       "checkpoint-87k      0.5454 +- 0.009      0.6687 +- 0.010  0.7543 +- 0.004   \n",
       "beto-cased          0.5836 +- 0.005      0.6846 +- 0.006  0.7477 +- 0.008   \n",
       "\n",
       "                  hate macro_f1 sentiment macro_f1 emotion macro_f1     score  \\\n",
       "model                                                                           \n",
       "bertin          0.7692 +- 0.005    0.6659 +- 0.003  0.5217 +- 0.014  0.628175   \n",
       "beto-uncased    0.7556 +- 0.011    0.6484 +- 0.005  0.5198 +- 0.006  0.628341   \n",
       "checkpoint-46k  0.7753 +- 0.007    0.6693 +- 0.002  0.5201 +- 0.008  0.622560   \n",
       "checkpoint-62k  0.7710 +- 0.009    0.6741 +- 0.002  0.5132 +- 0.015  0.618938   \n",
       "checkpoint-87k  0.7751 +- 0.008    0.6839 +- 0.007  0.5103 +- 0.011  0.628677   \n",
       "beto-cased      0.7647 +- 0.010    0.6647 +- 0.003  0.5258 +- 0.008  0.634689   \n",
       "\n",
       "                  score2  old_score  \n",
       "model                                \n",
       "bertin          0.652267   0.621988  \n",
       "beto-uncased    0.641274   0.623031  \n",
       "checkpoint-46k  0.654897   0.617082  \n",
       "checkpoint-62k  0.652757   0.613732  \n",
       "checkpoint-87k  0.656434   0.623480  \n",
       "beto-cased      0.651723   0.630432  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>score</th>\n",
       "      <th>score2</th>\n",
       "      <th>old_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5559 +- 0.002</td>\n",
       "      <td>0.6713 +- 0.002</td>\n",
       "      <td>0.7444 +- 0.004</td>\n",
       "      <td>0.7692 +- 0.005</td>\n",
       "      <td>0.6659 +- 0.003</td>\n",
       "      <td>0.5217 +- 0.014</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.652267</td>\n",
       "      <td>0.621988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5895 +- 0.006</td>\n",
       "      <td>0.6907 +- 0.005</td>\n",
       "      <td>0.7344 +- 0.007</td>\n",
       "      <td>0.7556 +- 0.011</td>\n",
       "      <td>0.6484 +- 0.005</td>\n",
       "      <td>0.5198 +- 0.006</td>\n",
       "      <td>0.628341</td>\n",
       "      <td>0.641274</td>\n",
       "      <td>0.623031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint-46k</th>\n",
       "      <td>0.5255 +- 0.006</td>\n",
       "      <td>0.6503 +- 0.006</td>\n",
       "      <td>0.7534 +- 0.003</td>\n",
       "      <td>0.7753 +- 0.007</td>\n",
       "      <td>0.6693 +- 0.002</td>\n",
       "      <td>0.5201 +- 0.008</td>\n",
       "      <td>0.622560</td>\n",
       "      <td>0.654897</td>\n",
       "      <td>0.617082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint-62k</th>\n",
       "      <td>0.5175 +- 0.021</td>\n",
       "      <td>0.6470 +- 0.018</td>\n",
       "      <td>0.7502 +- 0.004</td>\n",
       "      <td>0.7710 +- 0.009</td>\n",
       "      <td>0.6741 +- 0.002</td>\n",
       "      <td>0.5132 +- 0.015</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.652757</td>\n",
       "      <td>0.613732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint-87k</th>\n",
       "      <td>0.5454 +- 0.009</td>\n",
       "      <td>0.6687 +- 0.010</td>\n",
       "      <td>0.7543 +- 0.004</td>\n",
       "      <td>0.7751 +- 0.008</td>\n",
       "      <td>0.6839 +- 0.007</td>\n",
       "      <td>0.5103 +- 0.011</td>\n",
       "      <td>0.628677</td>\n",
       "      <td>0.656434</td>\n",
       "      <td>0.623480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5836 +- 0.005</td>\n",
       "      <td>0.6846 +- 0.006</td>\n",
       "      <td>0.7477 +- 0.008</td>\n",
       "      <td>0.7647 +- 0.010</td>\n",
       "      <td>0.6647 +- 0.003</td>\n",
       "      <td>0.5258 +- 0.008</td>\n",
       "      <td>0.634689</td>\n",
       "      <td>0.651723</td>\n",
       "      <td>0.630432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-cased\",\n",
    "    \"beto-uncased\",\n",
    "    \"beto-ft-1000\",\n",
    "    \"beto-ft-2000\",\n",
    "    \"beto-uncased-1000\",\n",
    "    \"beto-uncased-2000\",\n",
    "    \"beto-uncased-5000\",\n",
    "    \"beto-uncased-5000-grito\",\n",
    "    \"beto-uncased-4000-tpu\",\n",
    "    \"beto-uncased-5000-tpu\",\n",
    "    \"beto-uncased-15000\",\n",
    "    \"beto-uncased-15000-last\",\n",
    "    \"beto-cased-15000\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate hateful_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c]\n",
    "\n",
    "df.loc[order, columns]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        context_hate mean_f1 context_hate hate_f1  \\\n",
       "model                                                               \n",
       "bertin                       0.5443 +- 0.005      0.6613 +- 0.009   \n",
       "beto-cased                   0.5870 +- 0.007      0.6884 +- 0.005   \n",
       "beto-uncased                 0.5906 +- 0.004      0.6856 +- 0.006   \n",
       "beto-ft-1000                 0.5857 +- 0.003      0.6861 +- 0.002   \n",
       "beto-ft-2000                 0.5848 +- 0.005      0.6865 +- 0.003   \n",
       "beto-uncased-1000            0.5950 +- 0.003      0.6934 +- 0.002   \n",
       "beto-uncased-2000            0.5989 +- 0.004      0.6954 +- 0.002   \n",
       "beto-uncased-5000            0.5788 +- 0.001      0.6775 +- 0.004   \n",
       "beto-uncased-5000-grito      0.5848 +- 0.008      0.6866 +- 0.009   \n",
       "beto-uncased-4000-tpu        0.5884 +- 0.001      0.6875 +- 0.005   \n",
       "beto-uncased-5000-tpu        0.5853 +- 0.003      0.6835 +- 0.002   \n",
       "beto-uncased-15000           0.5854 +- 0.002      0.6833 +- 0.004   \n",
       "beto-uncased-15000-last      0.5775 +- 0.010      0.6827 +- 0.013   \n",
       "beto-cased-15000             0.5800 +- 0.004      0.6813 +- 0.003   \n",
       "\n",
       "                         hate hateful_f1    hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                          \n",
       "bertin                   0.7270 +- 0.013  0.7539 +- 0.013    0.6650 +- 0.002   \n",
       "beto-cased               0.7408 +- 0.013  0.7554 +- 0.021    0.6617 +- 0.005   \n",
       "beto-uncased             0.7305 +- 0.006  0.7455 +- 0.014    0.6517 +- 0.002   \n",
       "beto-ft-1000             0.7552 +- 0.011  0.7786 +- 0.012    0.6721 +- 0.001   \n",
       "beto-ft-2000             0.7486 +- 0.003  0.7691 +- 0.010    0.6751 +- 0.005   \n",
       "beto-uncased-1000        0.7451 +- 0.004  0.7703 +- 0.004    0.6717 +- 0.005   \n",
       "beto-uncased-2000        0.7575 +- 0.009  0.7729 +- 0.015    0.6812 +- 0.001   \n",
       "beto-uncased-5000        0.7623 +- 0.002  0.7854 +- 0.000    0.6748 +- 0.004   \n",
       "beto-uncased-5000-grito  0.7615 +- 0.006  0.7738 +- 0.010    0.6865 +- 0.005   \n",
       "beto-uncased-4000-tpu    0.7522 +- 0.009  0.7666 +- 0.006    0.6829 +- 0.001   \n",
       "beto-uncased-5000-tpu    0.7468 +- 0.014  0.7619 +- 0.014    0.6726 +- 0.009   \n",
       "beto-uncased-15000       0.7628 +- 0.006  0.7798 +- 0.006    0.6840 +- 0.006   \n",
       "beto-uncased-15000-last  0.7414 +- 0.012  0.7624 +- 0.014    0.6847 +- 0.002   \n",
       "beto-cased-15000         0.7566 +- 0.012  0.7750 +- 0.012    0.6860 +- 0.005   \n",
       "\n",
       "                        emotion macro_f1     score  \n",
       "model                                               \n",
       "bertin                   0.5245 +- 0.026  0.615193  \n",
       "beto-cased               0.5246 +- 0.016  0.628539  \n",
       "beto-uncased             0.5250 +- 0.014  0.624442  \n",
       "beto-ft-1000             0.5335 +- 0.012  0.636610  \n",
       "beto-ft-2000             0.5257 +- 0.010  0.633550  \n",
       "beto-uncased-1000        0.5364 +- 0.009  0.637067  \n",
       "beto-uncased-2000        0.5354 +- 0.005  0.643223  \n",
       "beto-uncased-5000        0.5399 +- 0.006  0.638945  \n",
       "beto-uncased-5000-grito  0.5522 +- 0.003  0.646247  \n",
       "beto-uncased-4000-tpu    0.5344 +- 0.008  0.639484  \n",
       "beto-uncased-5000-tpu    0.5563 +- 0.009  0.640264  \n",
       "beto-uncased-15000       0.5571 +- 0.003  0.647335  \n",
       "beto-uncased-15000-last  0.5454 +- 0.005  0.637237  \n",
       "beto-cased-15000         0.5338 +- 0.003  0.639121  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5443 +- 0.005</td>\n",
       "      <td>0.6613 +- 0.009</td>\n",
       "      <td>0.7270 +- 0.013</td>\n",
       "      <td>0.7539 +- 0.013</td>\n",
       "      <td>0.6650 +- 0.002</td>\n",
       "      <td>0.5245 +- 0.026</td>\n",
       "      <td>0.615193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5870 +- 0.007</td>\n",
       "      <td>0.6884 +- 0.005</td>\n",
       "      <td>0.7408 +- 0.013</td>\n",
       "      <td>0.7554 +- 0.021</td>\n",
       "      <td>0.6617 +- 0.005</td>\n",
       "      <td>0.5246 +- 0.016</td>\n",
       "      <td>0.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5906 +- 0.004</td>\n",
       "      <td>0.6856 +- 0.006</td>\n",
       "      <td>0.7305 +- 0.006</td>\n",
       "      <td>0.7455 +- 0.014</td>\n",
       "      <td>0.6517 +- 0.002</td>\n",
       "      <td>0.5250 +- 0.014</td>\n",
       "      <td>0.624442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-1000</th>\n",
       "      <td>0.5857 +- 0.003</td>\n",
       "      <td>0.6861 +- 0.002</td>\n",
       "      <td>0.7552 +- 0.011</td>\n",
       "      <td>0.7786 +- 0.012</td>\n",
       "      <td>0.6721 +- 0.001</td>\n",
       "      <td>0.5335 +- 0.012</td>\n",
       "      <td>0.636610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-2000</th>\n",
       "      <td>0.5848 +- 0.005</td>\n",
       "      <td>0.6865 +- 0.003</td>\n",
       "      <td>0.7486 +- 0.003</td>\n",
       "      <td>0.7691 +- 0.010</td>\n",
       "      <td>0.6751 +- 0.005</td>\n",
       "      <td>0.5257 +- 0.010</td>\n",
       "      <td>0.633550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-1000</th>\n",
       "      <td>0.5950 +- 0.003</td>\n",
       "      <td>0.6934 +- 0.002</td>\n",
       "      <td>0.7451 +- 0.004</td>\n",
       "      <td>0.7703 +- 0.004</td>\n",
       "      <td>0.6717 +- 0.005</td>\n",
       "      <td>0.5364 +- 0.009</td>\n",
       "      <td>0.637067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-2000</th>\n",
       "      <td>0.5989 +- 0.004</td>\n",
       "      <td>0.6954 +- 0.002</td>\n",
       "      <td>0.7575 +- 0.009</td>\n",
       "      <td>0.7729 +- 0.015</td>\n",
       "      <td>0.6812 +- 0.001</td>\n",
       "      <td>0.5354 +- 0.005</td>\n",
       "      <td>0.643223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000</th>\n",
       "      <td>0.5788 +- 0.001</td>\n",
       "      <td>0.6775 +- 0.004</td>\n",
       "      <td>0.7623 +- 0.002</td>\n",
       "      <td>0.7854 +- 0.000</td>\n",
       "      <td>0.6748 +- 0.004</td>\n",
       "      <td>0.5399 +- 0.006</td>\n",
       "      <td>0.638945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-grito</th>\n",
       "      <td>0.5848 +- 0.008</td>\n",
       "      <td>0.6866 +- 0.009</td>\n",
       "      <td>0.7615 +- 0.006</td>\n",
       "      <td>0.7738 +- 0.010</td>\n",
       "      <td>0.6865 +- 0.005</td>\n",
       "      <td>0.5522 +- 0.003</td>\n",
       "      <td>0.646247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-4000-tpu</th>\n",
       "      <td>0.5884 +- 0.001</td>\n",
       "      <td>0.6875 +- 0.005</td>\n",
       "      <td>0.7522 +- 0.009</td>\n",
       "      <td>0.7666 +- 0.006</td>\n",
       "      <td>0.6829 +- 0.001</td>\n",
       "      <td>0.5344 +- 0.008</td>\n",
       "      <td>0.639484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-tpu</th>\n",
       "      <td>0.5853 +- 0.003</td>\n",
       "      <td>0.6835 +- 0.002</td>\n",
       "      <td>0.7468 +- 0.014</td>\n",
       "      <td>0.7619 +- 0.014</td>\n",
       "      <td>0.6726 +- 0.009</td>\n",
       "      <td>0.5563 +- 0.009</td>\n",
       "      <td>0.640264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000</th>\n",
       "      <td>0.5854 +- 0.002</td>\n",
       "      <td>0.6833 +- 0.004</td>\n",
       "      <td>0.7628 +- 0.006</td>\n",
       "      <td>0.7798 +- 0.006</td>\n",
       "      <td>0.6840 +- 0.006</td>\n",
       "      <td>0.5571 +- 0.003</td>\n",
       "      <td>0.647335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000-last</th>\n",
       "      <td>0.5775 +- 0.010</td>\n",
       "      <td>0.6827 +- 0.013</td>\n",
       "      <td>0.7414 +- 0.012</td>\n",
       "      <td>0.7624 +- 0.014</td>\n",
       "      <td>0.6847 +- 0.002</td>\n",
       "      <td>0.5454 +- 0.005</td>\n",
       "      <td>0.637237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-15000</th>\n",
       "      <td>0.5800 +- 0.004</td>\n",
       "      <td>0.6813 +- 0.003</td>\n",
       "      <td>0.7566 +- 0.012</td>\n",
       "      <td>0.7750 +- 0.012</td>\n",
       "      <td>0.6860 +- 0.005</td>\n",
       "      <td>0.5338 +- 0.003</td>\n",
       "      <td>0.639121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- \"last\" es usando los mismos par√°metros que en el paper de finetuning\n",
    "\n",
    "No parecen ser los mejores!\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('finetune-vs-scratch-gHiQbun3-py3.8': poetry)"
  },
  "interpreter": {
   "hash": "28c1932dff7617228923490e32f133f79d588eb74ca6c2b1f196ab0fdc858ed2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}