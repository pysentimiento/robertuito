{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "outs = {}\n",
    "\n",
    "\n",
    "for filename in sorted([f for f in glob.glob(\"../output/*.json\") if \"test\" not in f]): \n",
    "    model_name = os.path.basename(filename).split(\".\")[0]\n",
    "    print(model_name)\n",
    "    with open(filename) as f:\n",
    "        outs[model_name] = json.load(f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bertin\n",
      "beto-cased-10000\n",
      "beto-cased-20000\n",
      "beto-cased-2500\n",
      "beto-cased-5000\n",
      "beto-cased\n",
      "beto-uncased-10000\n",
      "beto-uncased-20000\n",
      "beto-uncased-2500\n",
      "beto-uncased-5000\n",
      "beto-uncased\n",
      "checkpoint-100k\n",
      "checkpoint-124k\n",
      "checkpoint-46k\n",
      "checkpoint-62k\n",
      "checkpoint-87k\n",
      "roberta-bne\n",
      "robertuito-cased-574k\n",
      "robertuito-cased\n",
      "robertuito-uncased-200k\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"irony\": [\"eval_ironic_f1\", \"eval_macro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-uncased\",\n",
    "    \"beto-uncased-2500\",\n",
    "    \"beto-uncased-5000\",\n",
    "    \"beto-uncased-10000\",\n",
    "    \"beto-uncased-20000\",\n",
    "    #\"checkpoint-46k\",\n",
    "    #\"checkpoint-62k\",\n",
    "    #\"checkpoint-87k\",\n",
    "    #\"checkpoint-100k\",\n",
    "    #\"checkpoint-124k\",\n",
    "    \"robertuito-uncased-200k\",\n",
    "    \"beto-cased\",\n",
    "    \"beto-cased-2500\",\n",
    "    \"beto-cased-5000\",\n",
    "    \"beto-cased-10000\",\n",
    "    \"beto-cased-20000\",\n",
    "    \"robertuito-cased-574k\",\n",
    "    \"robertuito-cased\",\n",
    "    \"roberta-bne\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "score_without_chate_cols = [\"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "df.loc[order, \"score2\"] = df_mean.loc[order, score_without_chate_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c and \"score\" not in c] + [\"score\", \"score2\" ]\n",
    "\n",
    "df.loc[order, columns]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'irony' not in  beto-cased-10000\n",
      "'irony' not in  beto-cased-20000\n",
      "'irony' not in  beto-cased-2500\n",
      "'irony' not in  beto-cased-5000\n",
      "'irony' not in  beto-uncased-10000\n",
      "'irony' not in  beto-uncased-20000\n",
      "'irony' not in  beto-uncased-2500\n",
      "'irony' not in  beto-uncased-5000\n",
      "'irony' not in  checkpoint-100k\n",
      "'irony' not in  checkpoint-124k\n",
      "'irony' not in  checkpoint-46k\n",
      "'irony' not in  checkpoint-62k\n",
      "'irony' not in  checkpoint-87k\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>irony ironic_f1</th>\n",
       "      <th>irony macro_f1</th>\n",
       "      <th>score</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5559 +- 0.002</td>\n",
       "      <td>0.6713 +- 0.002</td>\n",
       "      <td>0.7444 +- 0.004</td>\n",
       "      <td>0.7692 +- 0.005</td>\n",
       "      <td>0.6659 +- 0.003</td>\n",
       "      <td>0.5217 +- 0.014</td>\n",
       "      <td>0.6089 +- 0.012</td>\n",
       "      <td>0.7131 +- 0.004</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.652267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5895 +- 0.006</td>\n",
       "      <td>0.6907 +- 0.005</td>\n",
       "      <td>0.7344 +- 0.007</td>\n",
       "      <td>0.7556 +- 0.011</td>\n",
       "      <td>0.6484 +- 0.005</td>\n",
       "      <td>0.5198 +- 0.006</td>\n",
       "      <td>0.5926 +- 0.011</td>\n",
       "      <td>0.7031 +- 0.007</td>\n",
       "      <td>0.628341</td>\n",
       "      <td>0.641274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-2500</th>\n",
       "      <td>0.5864 +- 0.004</td>\n",
       "      <td>0.6857 +- 0.006</td>\n",
       "      <td>0.7667 +- 0.008</td>\n",
       "      <td>0.7867 +- 0.011</td>\n",
       "      <td>0.6762 +- 0.006</td>\n",
       "      <td>0.5303 +- 0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644898</td>\n",
       "      <td>0.664394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000</th>\n",
       "      <td>0.5532 +- 0.012</td>\n",
       "      <td>0.6615 +- 0.008</td>\n",
       "      <td>0.7364 +- 0.004</td>\n",
       "      <td>0.7560 +- 0.009</td>\n",
       "      <td>0.6552 +- 0.005</td>\n",
       "      <td>0.5094 +- 0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618437</td>\n",
       "      <td>0.640197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-10000</th>\n",
       "      <td>0.5829 +- 0.004</td>\n",
       "      <td>0.6808 +- 0.005</td>\n",
       "      <td>0.7615 +- 0.007</td>\n",
       "      <td>0.7818 +- 0.006</td>\n",
       "      <td>0.6806 +- 0.005</td>\n",
       "      <td>0.5536 +- 0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649757</td>\n",
       "      <td>0.672043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-20000</th>\n",
       "      <td>0.5844 +- 0.007</td>\n",
       "      <td>0.6867 +- 0.005</td>\n",
       "      <td>0.7414 +- 0.015</td>\n",
       "      <td>0.7630 +- 0.011</td>\n",
       "      <td>0.6840 +- 0.006</td>\n",
       "      <td>0.5292 +- 0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640152</td>\n",
       "      <td>0.658732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-uncased-200k</th>\n",
       "      <td>0.5642 +- 0.005</td>\n",
       "      <td>0.6788 +- 0.006</td>\n",
       "      <td>0.7606 +- 0.007</td>\n",
       "      <td>0.7778 +- 0.012</td>\n",
       "      <td>0.6914 +- 0.003</td>\n",
       "      <td>0.5144 +- 0.007</td>\n",
       "      <td>0.6319 +- 0.019</td>\n",
       "      <td>0.7232 +- 0.006</td>\n",
       "      <td>0.636964</td>\n",
       "      <td>0.661216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5836 +- 0.005</td>\n",
       "      <td>0.6846 +- 0.006</td>\n",
       "      <td>0.7477 +- 0.008</td>\n",
       "      <td>0.7647 +- 0.010</td>\n",
       "      <td>0.6647 +- 0.003</td>\n",
       "      <td>0.5258 +- 0.008</td>\n",
       "      <td>0.6043 +- 0.012</td>\n",
       "      <td>0.7074 +- 0.007</td>\n",
       "      <td>0.634689</td>\n",
       "      <td>0.651723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-2500</th>\n",
       "      <td>0.5768 +- 0.002</td>\n",
       "      <td>0.6817 +- 0.004</td>\n",
       "      <td>0.7477 +- 0.008</td>\n",
       "      <td>0.7675 +- 0.006</td>\n",
       "      <td>0.6769 +- 0.006</td>\n",
       "      <td>0.5238 +- 0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636231</td>\n",
       "      <td>0.656037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-5000</th>\n",
       "      <td>0.5741 +- 0.003</td>\n",
       "      <td>0.6767 +- 0.001</td>\n",
       "      <td>0.7534 +- 0.007</td>\n",
       "      <td>0.7778 +- 0.008</td>\n",
       "      <td>0.6765 +- 0.005</td>\n",
       "      <td>0.5269 +- 0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>0.660409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-10000</th>\n",
       "      <td>0.5780 +- 0.004</td>\n",
       "      <td>0.6810 +- 0.004</td>\n",
       "      <td>0.7607 +- 0.009</td>\n",
       "      <td>0.7801 +- 0.009</td>\n",
       "      <td>0.6815 +- 0.005</td>\n",
       "      <td>0.5241 +- 0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640904</td>\n",
       "      <td>0.661884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-20000</th>\n",
       "      <td>0.5758 +- 0.004</td>\n",
       "      <td>0.6751 +- 0.003</td>\n",
       "      <td>0.7619 +- 0.005</td>\n",
       "      <td>0.7817 +- 0.005</td>\n",
       "      <td>0.6875 +- 0.005</td>\n",
       "      <td>0.5189 +- 0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640967</td>\n",
       "      <td>0.662689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-cased-574k</th>\n",
       "      <td>0.5880 +- 0.002</td>\n",
       "      <td>0.6903 +- 0.001</td>\n",
       "      <td>0.7563 +- 0.021</td>\n",
       "      <td>0.7840 +- 0.015</td>\n",
       "      <td>0.7006 +- 0.012</td>\n",
       "      <td>0.5195 +- 0.031</td>\n",
       "      <td>0.5716 +- 0.043</td>\n",
       "      <td>0.6989 +- 0.024</td>\n",
       "      <td>0.648056</td>\n",
       "      <td>0.668064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-cased</th>\n",
       "      <td>0.5893 +- 0.005</td>\n",
       "      <td>0.6918 +- 0.004</td>\n",
       "      <td>0.7664 +- 0.005</td>\n",
       "      <td>0.7905 +- 0.009</td>\n",
       "      <td>0.7018 +- 0.013</td>\n",
       "      <td>0.5143 +- 0.030</td>\n",
       "      <td>0.6048 +- 0.044</td>\n",
       "      <td>0.7150 +- 0.026</td>\n",
       "      <td>0.648977</td>\n",
       "      <td>0.668861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-bne</th>\n",
       "      <td>0.5770 +- 0.006</td>\n",
       "      <td>0.6782 +- 0.004</td>\n",
       "      <td>0.7485 +- 0.009</td>\n",
       "      <td>0.7628 +- 0.014</td>\n",
       "      <td>0.6711 +- 0.005</td>\n",
       "      <td>0.5290 +- 0.008</td>\n",
       "      <td>0.6292 +- 0.030</td>\n",
       "      <td>0.7229 +- 0.019</td>\n",
       "      <td>0.634973</td>\n",
       "      <td>0.654310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_hate mean_f1 context_hate hate_f1  \\\n",
       "model                                                               \n",
       "bertin                       0.5559 +- 0.002      0.6713 +- 0.002   \n",
       "beto-uncased                 0.5895 +- 0.006      0.6907 +- 0.005   \n",
       "beto-uncased-2500            0.5864 +- 0.004      0.6857 +- 0.006   \n",
       "beto-uncased-5000            0.5532 +- 0.012      0.6615 +- 0.008   \n",
       "beto-uncased-10000           0.5829 +- 0.004      0.6808 +- 0.005   \n",
       "beto-uncased-20000           0.5844 +- 0.007      0.6867 +- 0.005   \n",
       "robertuito-uncased-200k      0.5642 +- 0.005      0.6788 +- 0.006   \n",
       "beto-cased                   0.5836 +- 0.005      0.6846 +- 0.006   \n",
       "beto-cased-2500              0.5768 +- 0.002      0.6817 +- 0.004   \n",
       "beto-cased-5000              0.5741 +- 0.003      0.6767 +- 0.001   \n",
       "beto-cased-10000             0.5780 +- 0.004      0.6810 +- 0.004   \n",
       "beto-cased-20000             0.5758 +- 0.004      0.6751 +- 0.003   \n",
       "robertuito-cased-574k        0.5880 +- 0.002      0.6903 +- 0.001   \n",
       "robertuito-cased             0.5893 +- 0.005      0.6918 +- 0.004   \n",
       "roberta-bne                  0.5770 +- 0.006      0.6782 +- 0.004   \n",
       "\n",
       "                         hate hateful_f1    hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                          \n",
       "bertin                   0.7444 +- 0.004  0.7692 +- 0.005    0.6659 +- 0.003   \n",
       "beto-uncased             0.7344 +- 0.007  0.7556 +- 0.011    0.6484 +- 0.005   \n",
       "beto-uncased-2500        0.7667 +- 0.008  0.7867 +- 0.011    0.6762 +- 0.006   \n",
       "beto-uncased-5000        0.7364 +- 0.004  0.7560 +- 0.009    0.6552 +- 0.005   \n",
       "beto-uncased-10000       0.7615 +- 0.007  0.7818 +- 0.006    0.6806 +- 0.005   \n",
       "beto-uncased-20000       0.7414 +- 0.015  0.7630 +- 0.011    0.6840 +- 0.006   \n",
       "robertuito-uncased-200k  0.7606 +- 0.007  0.7778 +- 0.012    0.6914 +- 0.003   \n",
       "beto-cased               0.7477 +- 0.008  0.7647 +- 0.010    0.6647 +- 0.003   \n",
       "beto-cased-2500          0.7477 +- 0.008  0.7675 +- 0.006    0.6769 +- 0.006   \n",
       "beto-cased-5000          0.7534 +- 0.007  0.7778 +- 0.008    0.6765 +- 0.005   \n",
       "beto-cased-10000         0.7607 +- 0.009  0.7801 +- 0.009    0.6815 +- 0.005   \n",
       "beto-cased-20000         0.7619 +- 0.005  0.7817 +- 0.005    0.6875 +- 0.005   \n",
       "robertuito-cased-574k    0.7563 +- 0.021  0.7840 +- 0.015    0.7006 +- 0.012   \n",
       "robertuito-cased         0.7664 +- 0.005  0.7905 +- 0.009    0.7018 +- 0.013   \n",
       "roberta-bne              0.7485 +- 0.009  0.7628 +- 0.014    0.6711 +- 0.005   \n",
       "\n",
       "                        emotion macro_f1  irony ironic_f1   irony macro_f1  \\\n",
       "model                                                                        \n",
       "bertin                   0.5217 +- 0.014  0.6089 +- 0.012  0.7131 +- 0.004   \n",
       "beto-uncased             0.5198 +- 0.006  0.5926 +- 0.011  0.7031 +- 0.007   \n",
       "beto-uncased-2500        0.5303 +- 0.008              NaN              NaN   \n",
       "beto-uncased-5000        0.5094 +- 0.017              NaN              NaN   \n",
       "beto-uncased-10000       0.5536 +- 0.010              NaN              NaN   \n",
       "beto-uncased-20000       0.5292 +- 0.015              NaN              NaN   \n",
       "robertuito-uncased-200k  0.5144 +- 0.007  0.6319 +- 0.019  0.7232 +- 0.006   \n",
       "beto-cased               0.5258 +- 0.008  0.6043 +- 0.012  0.7074 +- 0.007   \n",
       "beto-cased-2500          0.5238 +- 0.010              NaN              NaN   \n",
       "beto-cased-5000          0.5269 +- 0.018              NaN              NaN   \n",
       "beto-cased-10000         0.5241 +- 0.007              NaN              NaN   \n",
       "beto-cased-20000         0.5189 +- 0.006              NaN              NaN   \n",
       "robertuito-cased-574k    0.5195 +- 0.031  0.5716 +- 0.043  0.6989 +- 0.024   \n",
       "robertuito-cased         0.5143 +- 0.030  0.6048 +- 0.044  0.7150 +- 0.026   \n",
       "roberta-bne              0.5290 +- 0.008  0.6292 +- 0.030  0.7229 +- 0.019   \n",
       "\n",
       "                            score    score2  \n",
       "model                                        \n",
       "bertin                   0.628175  0.652267  \n",
       "beto-uncased             0.628341  0.641274  \n",
       "beto-uncased-2500        0.644898  0.664394  \n",
       "beto-uncased-5000        0.618437  0.640197  \n",
       "beto-uncased-10000       0.649757  0.672043  \n",
       "beto-uncased-20000       0.640152  0.658732  \n",
       "robertuito-uncased-200k  0.636964  0.661216  \n",
       "beto-cased               0.634689  0.651723  \n",
       "beto-cased-2500          0.636231  0.656037  \n",
       "beto-cased-5000          0.638832  0.660409  \n",
       "beto-cased-10000         0.640904  0.661884  \n",
       "beto-cased-20000         0.640967  0.662689  \n",
       "robertuito-cased-574k    0.648056  0.668064  \n",
       "robertuito-cased         0.648977  0.668861  \n",
       "roberta-bne              0.634973  0.654310  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-cased\",\n",
    "    \"beto-uncased\",\n",
    "    \"beto-ft-1000\",\n",
    "    \"beto-ft-2000\",\n",
    "    \"beto-uncased-1000\",\n",
    "    \"beto-uncased-2000\",\n",
    "    \"beto-uncased-5000\",\n",
    "    \"beto-uncased-5000-grito\",\n",
    "    \"beto-uncased-4000-tpu\",\n",
    "    \"beto-uncased-5000-tpu\",\n",
    "    \"beto-uncased-15000\",\n",
    "    \"beto-uncased-15000-last\",\n",
    "    \"beto-cased-15000\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate hateful_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c]\n",
    "\n",
    "df.loc[order, columns]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5443 +- 0.005</td>\n",
       "      <td>0.6613 +- 0.009</td>\n",
       "      <td>0.7270 +- 0.013</td>\n",
       "      <td>0.7539 +- 0.013</td>\n",
       "      <td>0.6650 +- 0.002</td>\n",
       "      <td>0.5245 +- 0.026</td>\n",
       "      <td>0.615193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5870 +- 0.007</td>\n",
       "      <td>0.6884 +- 0.005</td>\n",
       "      <td>0.7408 +- 0.013</td>\n",
       "      <td>0.7554 +- 0.021</td>\n",
       "      <td>0.6617 +- 0.005</td>\n",
       "      <td>0.5246 +- 0.016</td>\n",
       "      <td>0.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5906 +- 0.004</td>\n",
       "      <td>0.6856 +- 0.006</td>\n",
       "      <td>0.7305 +- 0.006</td>\n",
       "      <td>0.7455 +- 0.014</td>\n",
       "      <td>0.6517 +- 0.002</td>\n",
       "      <td>0.5250 +- 0.014</td>\n",
       "      <td>0.624442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-1000</th>\n",
       "      <td>0.5857 +- 0.003</td>\n",
       "      <td>0.6861 +- 0.002</td>\n",
       "      <td>0.7552 +- 0.011</td>\n",
       "      <td>0.7786 +- 0.012</td>\n",
       "      <td>0.6721 +- 0.001</td>\n",
       "      <td>0.5335 +- 0.012</td>\n",
       "      <td>0.636610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-2000</th>\n",
       "      <td>0.5848 +- 0.005</td>\n",
       "      <td>0.6865 +- 0.003</td>\n",
       "      <td>0.7486 +- 0.003</td>\n",
       "      <td>0.7691 +- 0.010</td>\n",
       "      <td>0.6751 +- 0.005</td>\n",
       "      <td>0.5257 +- 0.010</td>\n",
       "      <td>0.633550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-1000</th>\n",
       "      <td>0.5950 +- 0.003</td>\n",
       "      <td>0.6934 +- 0.002</td>\n",
       "      <td>0.7451 +- 0.004</td>\n",
       "      <td>0.7703 +- 0.004</td>\n",
       "      <td>0.6717 +- 0.005</td>\n",
       "      <td>0.5364 +- 0.009</td>\n",
       "      <td>0.637067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-2000</th>\n",
       "      <td>0.5989 +- 0.004</td>\n",
       "      <td>0.6954 +- 0.002</td>\n",
       "      <td>0.7575 +- 0.009</td>\n",
       "      <td>0.7729 +- 0.015</td>\n",
       "      <td>0.6812 +- 0.001</td>\n",
       "      <td>0.5354 +- 0.005</td>\n",
       "      <td>0.643223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000</th>\n",
       "      <td>0.5788 +- 0.001</td>\n",
       "      <td>0.6775 +- 0.004</td>\n",
       "      <td>0.7623 +- 0.002</td>\n",
       "      <td>0.7854 +- 0.000</td>\n",
       "      <td>0.6748 +- 0.004</td>\n",
       "      <td>0.5399 +- 0.006</td>\n",
       "      <td>0.638945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-grito</th>\n",
       "      <td>0.5848 +- 0.008</td>\n",
       "      <td>0.6866 +- 0.009</td>\n",
       "      <td>0.7615 +- 0.006</td>\n",
       "      <td>0.7738 +- 0.010</td>\n",
       "      <td>0.6865 +- 0.005</td>\n",
       "      <td>0.5522 +- 0.003</td>\n",
       "      <td>0.646247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-4000-tpu</th>\n",
       "      <td>0.5884 +- 0.001</td>\n",
       "      <td>0.6875 +- 0.005</td>\n",
       "      <td>0.7522 +- 0.009</td>\n",
       "      <td>0.7666 +- 0.006</td>\n",
       "      <td>0.6829 +- 0.001</td>\n",
       "      <td>0.5344 +- 0.008</td>\n",
       "      <td>0.639484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-tpu</th>\n",
       "      <td>0.5853 +- 0.003</td>\n",
       "      <td>0.6835 +- 0.002</td>\n",
       "      <td>0.7468 +- 0.014</td>\n",
       "      <td>0.7619 +- 0.014</td>\n",
       "      <td>0.6726 +- 0.009</td>\n",
       "      <td>0.5563 +- 0.009</td>\n",
       "      <td>0.640264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000</th>\n",
       "      <td>0.5854 +- 0.002</td>\n",
       "      <td>0.6833 +- 0.004</td>\n",
       "      <td>0.7628 +- 0.006</td>\n",
       "      <td>0.7798 +- 0.006</td>\n",
       "      <td>0.6840 +- 0.006</td>\n",
       "      <td>0.5571 +- 0.003</td>\n",
       "      <td>0.647335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000-last</th>\n",
       "      <td>0.5775 +- 0.010</td>\n",
       "      <td>0.6827 +- 0.013</td>\n",
       "      <td>0.7414 +- 0.012</td>\n",
       "      <td>0.7624 +- 0.014</td>\n",
       "      <td>0.6847 +- 0.002</td>\n",
       "      <td>0.5454 +- 0.005</td>\n",
       "      <td>0.637237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-15000</th>\n",
       "      <td>0.5800 +- 0.004</td>\n",
       "      <td>0.6813 +- 0.003</td>\n",
       "      <td>0.7566 +- 0.012</td>\n",
       "      <td>0.7750 +- 0.012</td>\n",
       "      <td>0.6860 +- 0.005</td>\n",
       "      <td>0.5338 +- 0.003</td>\n",
       "      <td>0.639121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_hate mean_f1 context_hate hate_f1  \\\n",
       "model                                                               \n",
       "bertin                       0.5443 +- 0.005      0.6613 +- 0.009   \n",
       "beto-cased                   0.5870 +- 0.007      0.6884 +- 0.005   \n",
       "beto-uncased                 0.5906 +- 0.004      0.6856 +- 0.006   \n",
       "beto-ft-1000                 0.5857 +- 0.003      0.6861 +- 0.002   \n",
       "beto-ft-2000                 0.5848 +- 0.005      0.6865 +- 0.003   \n",
       "beto-uncased-1000            0.5950 +- 0.003      0.6934 +- 0.002   \n",
       "beto-uncased-2000            0.5989 +- 0.004      0.6954 +- 0.002   \n",
       "beto-uncased-5000            0.5788 +- 0.001      0.6775 +- 0.004   \n",
       "beto-uncased-5000-grito      0.5848 +- 0.008      0.6866 +- 0.009   \n",
       "beto-uncased-4000-tpu        0.5884 +- 0.001      0.6875 +- 0.005   \n",
       "beto-uncased-5000-tpu        0.5853 +- 0.003      0.6835 +- 0.002   \n",
       "beto-uncased-15000           0.5854 +- 0.002      0.6833 +- 0.004   \n",
       "beto-uncased-15000-last      0.5775 +- 0.010      0.6827 +- 0.013   \n",
       "beto-cased-15000             0.5800 +- 0.004      0.6813 +- 0.003   \n",
       "\n",
       "                         hate hateful_f1    hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                          \n",
       "bertin                   0.7270 +- 0.013  0.7539 +- 0.013    0.6650 +- 0.002   \n",
       "beto-cased               0.7408 +- 0.013  0.7554 +- 0.021    0.6617 +- 0.005   \n",
       "beto-uncased             0.7305 +- 0.006  0.7455 +- 0.014    0.6517 +- 0.002   \n",
       "beto-ft-1000             0.7552 +- 0.011  0.7786 +- 0.012    0.6721 +- 0.001   \n",
       "beto-ft-2000             0.7486 +- 0.003  0.7691 +- 0.010    0.6751 +- 0.005   \n",
       "beto-uncased-1000        0.7451 +- 0.004  0.7703 +- 0.004    0.6717 +- 0.005   \n",
       "beto-uncased-2000        0.7575 +- 0.009  0.7729 +- 0.015    0.6812 +- 0.001   \n",
       "beto-uncased-5000        0.7623 +- 0.002  0.7854 +- 0.000    0.6748 +- 0.004   \n",
       "beto-uncased-5000-grito  0.7615 +- 0.006  0.7738 +- 0.010    0.6865 +- 0.005   \n",
       "beto-uncased-4000-tpu    0.7522 +- 0.009  0.7666 +- 0.006    0.6829 +- 0.001   \n",
       "beto-uncased-5000-tpu    0.7468 +- 0.014  0.7619 +- 0.014    0.6726 +- 0.009   \n",
       "beto-uncased-15000       0.7628 +- 0.006  0.7798 +- 0.006    0.6840 +- 0.006   \n",
       "beto-uncased-15000-last  0.7414 +- 0.012  0.7624 +- 0.014    0.6847 +- 0.002   \n",
       "beto-cased-15000         0.7566 +- 0.012  0.7750 +- 0.012    0.6860 +- 0.005   \n",
       "\n",
       "                        emotion macro_f1     score  \n",
       "model                                               \n",
       "bertin                   0.5245 +- 0.026  0.615193  \n",
       "beto-cased               0.5246 +- 0.016  0.628539  \n",
       "beto-uncased             0.5250 +- 0.014  0.624442  \n",
       "beto-ft-1000             0.5335 +- 0.012  0.636610  \n",
       "beto-ft-2000             0.5257 +- 0.010  0.633550  \n",
       "beto-uncased-1000        0.5364 +- 0.009  0.637067  \n",
       "beto-uncased-2000        0.5354 +- 0.005  0.643223  \n",
       "beto-uncased-5000        0.5399 +- 0.006  0.638945  \n",
       "beto-uncased-5000-grito  0.5522 +- 0.003  0.646247  \n",
       "beto-uncased-4000-tpu    0.5344 +- 0.008  0.639484  \n",
       "beto-uncased-5000-tpu    0.5563 +- 0.009  0.640264  \n",
       "beto-uncased-15000       0.5571 +- 0.003  0.647335  \n",
       "beto-uncased-15000-last  0.5454 +- 0.005  0.637237  \n",
       "beto-cased-15000         0.5338 +- 0.003  0.639121  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- \"last\" es usando los mismos par√°metros que en el paper de finetuning\n",
    "\n",
    "No parecen ser los mejores!\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('finetune-vs-scratch-gHiQbun3-py3.8': poetry)"
  },
  "interpreter": {
   "hash": "28c1932dff7617228923490e32f133f79d588eb74ca6c2b1f196ab0fdc858ed2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}