{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertin\n",
      "beto-cased-10000\n",
      "beto-cased-20000\n",
      "beto-cased-2500\n",
      "beto-cased-5000\n",
      "beto-cased\n",
      "beto-uncased-10000\n",
      "beto-uncased-20000\n",
      "beto-uncased-2500\n",
      "beto-uncased-5000\n",
      "beto-uncased\n",
      "checkpoint-100k\n",
      "checkpoint-124k\n",
      "checkpoint-46k\n",
      "checkpoint-62k\n",
      "checkpoint-87k\n",
      "roberta-bne\n",
      "robertuito-cased\n",
      "robertuito-deacc-288k\n",
      "robertuito-deacc-344k\n",
      "robertuito-deacc-400k\n",
      "robertuito-deacc-440k\n",
      "robertuito-deacc-490k\n",
      "robertuito-deacc-510k\n",
      "robertuito-deacc-540k\n",
      "robertuito-deacc-571k\n",
      "robertuito-deacc-576k\n",
      "robertuito-deacc-592k\n",
      "robertuito-deacc\n",
      "robertuito-uncased-200k\n",
      "robertuito-uncased\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "outs = {}\n",
    "\n",
    "\n",
    "for filename in sorted([f for f in glob.glob(\"../output/*.json\") if \"test\" not in f]): \n",
    "    model_name = os.path.basename(filename).split(\".\")[0]\n",
    "    print(model_name)\n",
    "    with open(filename) as f:\n",
    "        outs[model_name] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'irony' not in  checkpoint-100k\n",
      "'irony' not in  checkpoint-124k\n",
      "'irony' not in  checkpoint-46k\n",
      "'irony' not in  checkpoint-62k\n",
      "'irony' not in  checkpoint-87k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>irony macro_f1</th>\n",
       "      <th>score</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.590 +- 0.006</td>\n",
       "      <td>0.756 +- 0.011</td>\n",
       "      <td>0.648 +- 0.005</td>\n",
       "      <td>0.520 +- 0.006</td>\n",
       "      <td>0.703 +- 0.007</td>\n",
       "      <td>0.643285</td>\n",
       "      <td>0.656722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.558 +- 0.008</td>\n",
       "      <td>0.766 +- 0.005</td>\n",
       "      <td>0.664 +- 0.003</td>\n",
       "      <td>0.517 +- 0.011</td>\n",
       "      <td>0.715 +- 0.008</td>\n",
       "      <td>0.644139</td>\n",
       "      <td>0.665697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.584 +- 0.005</td>\n",
       "      <td>0.765 +- 0.010</td>\n",
       "      <td>0.665 +- 0.003</td>\n",
       "      <td>0.526 +- 0.008</td>\n",
       "      <td>0.707 +- 0.007</td>\n",
       "      <td>0.649226</td>\n",
       "      <td>0.665636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-bne</th>\n",
       "      <td>0.578 +- 0.004</td>\n",
       "      <td>0.767 +- 0.015</td>\n",
       "      <td>0.667 +- 0.007</td>\n",
       "      <td>0.535 +- 0.012</td>\n",
       "      <td>0.723 +- 0.016</td>\n",
       "      <td>0.654161</td>\n",
       "      <td>0.673217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-5000</th>\n",
       "      <td>0.576 +- 0.002</td>\n",
       "      <td>0.783 +- 0.010</td>\n",
       "      <td>0.677 +- 0.004</td>\n",
       "      <td>0.524 +- 0.015</td>\n",
       "      <td>0.723 +- 0.008</td>\n",
       "      <td>0.656472</td>\n",
       "      <td>0.676619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-10000</th>\n",
       "      <td>0.589 +- 0.003</td>\n",
       "      <td>0.772 +- 0.017</td>\n",
       "      <td>0.680 +- 0.004</td>\n",
       "      <td>0.553 +- 0.008</td>\n",
       "      <td>0.716 +- 0.006</td>\n",
       "      <td>0.661718</td>\n",
       "      <td>0.679986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-cased</th>\n",
       "      <td>0.590 +- 0.005</td>\n",
       "      <td>0.789 +- 0.014</td>\n",
       "      <td>0.700 +- 0.012</td>\n",
       "      <td>0.521 +- 0.032</td>\n",
       "      <td>0.722 +- 0.021</td>\n",
       "      <td>0.664466</td>\n",
       "      <td>0.683070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-deacc</th>\n",
       "      <td>0.594 +- 0.006</td>\n",
       "      <td>0.800 +- 0.008</td>\n",
       "      <td>0.702 +- 0.004</td>\n",
       "      <td>0.545 +- 0.013</td>\n",
       "      <td>0.739 +- 0.005</td>\n",
       "      <td>0.675947</td>\n",
       "      <td>0.696315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-uncased</th>\n",
       "      <td>0.592 +- 0.005</td>\n",
       "      <td>0.800 +- 0.008</td>\n",
       "      <td>0.707 +- 0.005</td>\n",
       "      <td>0.546 +- 0.011</td>\n",
       "      <td>0.737 +- 0.009</td>\n",
       "      <td>0.676655</td>\n",
       "      <td>0.697717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   context_hate mean_f1   hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                        \n",
       "beto-uncased             0.590 +- 0.006  0.756 +- 0.011     0.648 +- 0.005   \n",
       "bertin                   0.558 +- 0.008  0.766 +- 0.005     0.664 +- 0.003   \n",
       "beto-cased               0.584 +- 0.005  0.765 +- 0.010     0.665 +- 0.003   \n",
       "roberta-bne              0.578 +- 0.004  0.767 +- 0.015     0.667 +- 0.007   \n",
       "beto-cased-5000          0.576 +- 0.002  0.783 +- 0.010     0.677 +- 0.004   \n",
       "beto-uncased-10000       0.589 +- 0.003  0.772 +- 0.017     0.680 +- 0.004   \n",
       "robertuito-cased         0.590 +- 0.005  0.789 +- 0.014     0.700 +- 0.012   \n",
       "robertuito-deacc         0.594 +- 0.006  0.800 +- 0.008     0.702 +- 0.004   \n",
       "robertuito-uncased       0.592 +- 0.005  0.800 +- 0.008     0.707 +- 0.005   \n",
       "\n",
       "                   emotion macro_f1  irony macro_f1     score    score2  \n",
       "model                                                                    \n",
       "beto-uncased         0.520 +- 0.006  0.703 +- 0.007  0.643285  0.656722  \n",
       "bertin               0.517 +- 0.011  0.715 +- 0.008  0.644139  0.665697  \n",
       "beto-cased           0.526 +- 0.008  0.707 +- 0.007  0.649226  0.665636  \n",
       "roberta-bne          0.535 +- 0.012  0.723 +- 0.016  0.654161  0.673217  \n",
       "beto-cased-5000      0.524 +- 0.015  0.723 +- 0.008  0.656472  0.676619  \n",
       "beto-uncased-10000   0.553 +- 0.008  0.716 +- 0.006  0.661718  0.679986  \n",
       "robertuito-cased     0.521 +- 0.032  0.722 +- 0.021  0.664466  0.683070  \n",
       "robertuito-deacc     0.545 +- 0.013  0.739 +- 0.005  0.675947  0.696315  \n",
       "robertuito-uncased   0.546 +- 0.011  0.737 +- 0.009  0.676655  0.697717  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"irony\": [\"eval_ironic_f1\", \"eval_macro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.3f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"roberta-bne\",\n",
    "    \"beto-uncased\",\n",
    "    # Nos quedamos con uncased-10000 que es el mejor\n",
    "    #\"beto-uncased-2500\",\n",
    "    #\"beto-uncased-5000\",\n",
    "    \"beto-uncased-10000\",\n",
    "    #\"beto-uncased-20000\",\n",
    "    \"robertuito-uncased\",\n",
    "    #\"robertuito-deacc-288k\",\n",
    "    #\"robertuito-deacc-344k\",\n",
    "    #\"robertuito-deacc-400k\",\n",
    "    #\"robertuito-deacc-440k\",\n",
    "    #\"robertuito-deacc-490k\",\n",
    "    #\"robertuito-deacc-510k\",\n",
    "    #\"robertuito-deacc-540k\",\n",
    "    #\"robertuito-deacc-576k\",\n",
    "    #\"robertuito-deacc-592k\",\n",
    "    \"robertuito-deacc\",\n",
    "    #\"checkpoint-46k\",\n",
    "    #\"checkpoint-62k\",\n",
    "    #\"checkpoint-87k\",\n",
    "    #\"checkpoint-100k\",\n",
    "    #\"checkpoint-124k\",\n",
    "    #\"robertuito-uncased-200k\",\n",
    "    \"beto-cased\",\n",
    "    #\"beto-cased-2500\",\n",
    "    \"beto-cased-5000\",\n",
    "    #\"beto-cased-10000\",\n",
    "    #\"beto-cased-20000\",\n",
    "    \"robertuito-cased\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\", \"irony macro_f1\"]\n",
    "score_without_chate_cols = [\"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\", \"irony macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "df.loc[order, \"score2\"] = df_mean.loc[order, score_without_chate_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c and \"score\" not in c] + [\"score\", \"score2\" ]\n",
    "\n",
    "df.loc[order, score_cols + [\"score\", \"score2\"]].sort_values(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllr}\n",
      "\\toprule\n",
      "{} & context\\_hate mean\\_f1 &   hate macro\\_f1 & sentiment macro\\_f1 & emotion macro\\_f1 &  irony macro\\_f1 &     score \\\\\n",
      "model              &                      &                 &                    &                  &                 &           \\\\\n",
      "\\midrule\n",
      "beto-uncased       &       0.590 +- 0.006 &  0.756 +- 0.011 &     0.648 +- 0.005 &   0.520 +- 0.006 &  0.703 +- 0.007 &  0.643285 \\\\\n",
      "bertin             &       0.558 +- 0.008 &  0.766 +- 0.005 &     0.664 +- 0.003 &   0.517 +- 0.011 &  0.715 +- 0.008 &  0.644139 \\\\\n",
      "beto-cased         &       0.584 +- 0.005 &  0.765 +- 0.010 &     0.665 +- 0.003 &   0.526 +- 0.008 &  0.707 +- 0.007 &  0.649226 \\\\\n",
      "roberta-bne        &       0.578 +- 0.004 &  0.767 +- 0.015 &     0.667 +- 0.007 &   0.535 +- 0.012 &  0.723 +- 0.016 &  0.654161 \\\\\n",
      "beto-cased-5000    &       0.576 +- 0.002 &  0.783 +- 0.010 &     0.677 +- 0.004 &   0.524 +- 0.015 &  0.723 +- 0.008 &  0.656472 \\\\\n",
      "beto-uncased-10000 &       0.589 +- 0.003 &  0.772 +- 0.017 &     0.680 +- 0.004 &   0.553 +- 0.008 &  0.716 +- 0.006 &  0.661718 \\\\\n",
      "robertuito-cased   &       0.590 +- 0.005 &  0.789 +- 0.014 &     0.700 +- 0.012 &   0.521 +- 0.032 &  0.722 +- 0.021 &  0.664466 \\\\\n",
      "robertuito-deacc   &       0.594 +- 0.006 &  0.800 +- 0.008 &     0.702 +- 0.004 &   0.545 +- 0.013 &  0.739 +- 0.005 &  0.675947 \\\\\n",
      "robertuito-uncased &       0.592 +- 0.005 &  0.800 +- 0.008 &     0.707 +- 0.005 &   0.546 +- 0.011 &  0.737 +- 0.009 &  0.676655 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[order, score_cols + [\"score\"]].sort_values(\"score\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5443 +- 0.005</td>\n",
       "      <td>0.6613 +- 0.009</td>\n",
       "      <td>0.7270 +- 0.013</td>\n",
       "      <td>0.7539 +- 0.013</td>\n",
       "      <td>0.6650 +- 0.002</td>\n",
       "      <td>0.5245 +- 0.026</td>\n",
       "      <td>0.615193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5870 +- 0.007</td>\n",
       "      <td>0.6884 +- 0.005</td>\n",
       "      <td>0.7408 +- 0.013</td>\n",
       "      <td>0.7554 +- 0.021</td>\n",
       "      <td>0.6617 +- 0.005</td>\n",
       "      <td>0.5246 +- 0.016</td>\n",
       "      <td>0.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5906 +- 0.004</td>\n",
       "      <td>0.6856 +- 0.006</td>\n",
       "      <td>0.7305 +- 0.006</td>\n",
       "      <td>0.7455 +- 0.014</td>\n",
       "      <td>0.6517 +- 0.002</td>\n",
       "      <td>0.5250 +- 0.014</td>\n",
       "      <td>0.624442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-1000</th>\n",
       "      <td>0.5857 +- 0.003</td>\n",
       "      <td>0.6861 +- 0.002</td>\n",
       "      <td>0.7552 +- 0.011</td>\n",
       "      <td>0.7786 +- 0.012</td>\n",
       "      <td>0.6721 +- 0.001</td>\n",
       "      <td>0.5335 +- 0.012</td>\n",
       "      <td>0.636610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-2000</th>\n",
       "      <td>0.5848 +- 0.005</td>\n",
       "      <td>0.6865 +- 0.003</td>\n",
       "      <td>0.7486 +- 0.003</td>\n",
       "      <td>0.7691 +- 0.010</td>\n",
       "      <td>0.6751 +- 0.005</td>\n",
       "      <td>0.5257 +- 0.010</td>\n",
       "      <td>0.633550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-1000</th>\n",
       "      <td>0.5950 +- 0.003</td>\n",
       "      <td>0.6934 +- 0.002</td>\n",
       "      <td>0.7451 +- 0.004</td>\n",
       "      <td>0.7703 +- 0.004</td>\n",
       "      <td>0.6717 +- 0.005</td>\n",
       "      <td>0.5364 +- 0.009</td>\n",
       "      <td>0.637067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-2000</th>\n",
       "      <td>0.5989 +- 0.004</td>\n",
       "      <td>0.6954 +- 0.002</td>\n",
       "      <td>0.7575 +- 0.009</td>\n",
       "      <td>0.7729 +- 0.015</td>\n",
       "      <td>0.6812 +- 0.001</td>\n",
       "      <td>0.5354 +- 0.005</td>\n",
       "      <td>0.643223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000</th>\n",
       "      <td>0.5788 +- 0.001</td>\n",
       "      <td>0.6775 +- 0.004</td>\n",
       "      <td>0.7623 +- 0.002</td>\n",
       "      <td>0.7854 +- 0.000</td>\n",
       "      <td>0.6748 +- 0.004</td>\n",
       "      <td>0.5399 +- 0.006</td>\n",
       "      <td>0.638945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-grito</th>\n",
       "      <td>0.5848 +- 0.008</td>\n",
       "      <td>0.6866 +- 0.009</td>\n",
       "      <td>0.7615 +- 0.006</td>\n",
       "      <td>0.7738 +- 0.010</td>\n",
       "      <td>0.6865 +- 0.005</td>\n",
       "      <td>0.5522 +- 0.003</td>\n",
       "      <td>0.646247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-4000-tpu</th>\n",
       "      <td>0.5884 +- 0.001</td>\n",
       "      <td>0.6875 +- 0.005</td>\n",
       "      <td>0.7522 +- 0.009</td>\n",
       "      <td>0.7666 +- 0.006</td>\n",
       "      <td>0.6829 +- 0.001</td>\n",
       "      <td>0.5344 +- 0.008</td>\n",
       "      <td>0.639484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-tpu</th>\n",
       "      <td>0.5853 +- 0.003</td>\n",
       "      <td>0.6835 +- 0.002</td>\n",
       "      <td>0.7468 +- 0.014</td>\n",
       "      <td>0.7619 +- 0.014</td>\n",
       "      <td>0.6726 +- 0.009</td>\n",
       "      <td>0.5563 +- 0.009</td>\n",
       "      <td>0.640264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000</th>\n",
       "      <td>0.5854 +- 0.002</td>\n",
       "      <td>0.6833 +- 0.004</td>\n",
       "      <td>0.7628 +- 0.006</td>\n",
       "      <td>0.7798 +- 0.006</td>\n",
       "      <td>0.6840 +- 0.006</td>\n",
       "      <td>0.5571 +- 0.003</td>\n",
       "      <td>0.647335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000-last</th>\n",
       "      <td>0.5775 +- 0.010</td>\n",
       "      <td>0.6827 +- 0.013</td>\n",
       "      <td>0.7414 +- 0.012</td>\n",
       "      <td>0.7624 +- 0.014</td>\n",
       "      <td>0.6847 +- 0.002</td>\n",
       "      <td>0.5454 +- 0.005</td>\n",
       "      <td>0.637237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-15000</th>\n",
       "      <td>0.5800 +- 0.004</td>\n",
       "      <td>0.6813 +- 0.003</td>\n",
       "      <td>0.7566 +- 0.012</td>\n",
       "      <td>0.7750 +- 0.012</td>\n",
       "      <td>0.6860 +- 0.005</td>\n",
       "      <td>0.5338 +- 0.003</td>\n",
       "      <td>0.639121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_hate mean_f1 context_hate hate_f1  \\\n",
       "model                                                               \n",
       "bertin                       0.5443 +- 0.005      0.6613 +- 0.009   \n",
       "beto-cased                   0.5870 +- 0.007      0.6884 +- 0.005   \n",
       "beto-uncased                 0.5906 +- 0.004      0.6856 +- 0.006   \n",
       "beto-ft-1000                 0.5857 +- 0.003      0.6861 +- 0.002   \n",
       "beto-ft-2000                 0.5848 +- 0.005      0.6865 +- 0.003   \n",
       "beto-uncased-1000            0.5950 +- 0.003      0.6934 +- 0.002   \n",
       "beto-uncased-2000            0.5989 +- 0.004      0.6954 +- 0.002   \n",
       "beto-uncased-5000            0.5788 +- 0.001      0.6775 +- 0.004   \n",
       "beto-uncased-5000-grito      0.5848 +- 0.008      0.6866 +- 0.009   \n",
       "beto-uncased-4000-tpu        0.5884 +- 0.001      0.6875 +- 0.005   \n",
       "beto-uncased-5000-tpu        0.5853 +- 0.003      0.6835 +- 0.002   \n",
       "beto-uncased-15000           0.5854 +- 0.002      0.6833 +- 0.004   \n",
       "beto-uncased-15000-last      0.5775 +- 0.010      0.6827 +- 0.013   \n",
       "beto-cased-15000             0.5800 +- 0.004      0.6813 +- 0.003   \n",
       "\n",
       "                         hate hateful_f1    hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                          \n",
       "bertin                   0.7270 +- 0.013  0.7539 +- 0.013    0.6650 +- 0.002   \n",
       "beto-cased               0.7408 +- 0.013  0.7554 +- 0.021    0.6617 +- 0.005   \n",
       "beto-uncased             0.7305 +- 0.006  0.7455 +- 0.014    0.6517 +- 0.002   \n",
       "beto-ft-1000             0.7552 +- 0.011  0.7786 +- 0.012    0.6721 +- 0.001   \n",
       "beto-ft-2000             0.7486 +- 0.003  0.7691 +- 0.010    0.6751 +- 0.005   \n",
       "beto-uncased-1000        0.7451 +- 0.004  0.7703 +- 0.004    0.6717 +- 0.005   \n",
       "beto-uncased-2000        0.7575 +- 0.009  0.7729 +- 0.015    0.6812 +- 0.001   \n",
       "beto-uncased-5000        0.7623 +- 0.002  0.7854 +- 0.000    0.6748 +- 0.004   \n",
       "beto-uncased-5000-grito  0.7615 +- 0.006  0.7738 +- 0.010    0.6865 +- 0.005   \n",
       "beto-uncased-4000-tpu    0.7522 +- 0.009  0.7666 +- 0.006    0.6829 +- 0.001   \n",
       "beto-uncased-5000-tpu    0.7468 +- 0.014  0.7619 +- 0.014    0.6726 +- 0.009   \n",
       "beto-uncased-15000       0.7628 +- 0.006  0.7798 +- 0.006    0.6840 +- 0.006   \n",
       "beto-uncased-15000-last  0.7414 +- 0.012  0.7624 +- 0.014    0.6847 +- 0.002   \n",
       "beto-cased-15000         0.7566 +- 0.012  0.7750 +- 0.012    0.6860 +- 0.005   \n",
       "\n",
       "                        emotion macro_f1     score  \n",
       "model                                               \n",
       "bertin                   0.5245 +- 0.026  0.615193  \n",
       "beto-cased               0.5246 +- 0.016  0.628539  \n",
       "beto-uncased             0.5250 +- 0.014  0.624442  \n",
       "beto-ft-1000             0.5335 +- 0.012  0.636610  \n",
       "beto-ft-2000             0.5257 +- 0.010  0.633550  \n",
       "beto-uncased-1000        0.5364 +- 0.009  0.637067  \n",
       "beto-uncased-2000        0.5354 +- 0.005  0.643223  \n",
       "beto-uncased-5000        0.5399 +- 0.006  0.638945  \n",
       "beto-uncased-5000-grito  0.5522 +- 0.003  0.646247  \n",
       "beto-uncased-4000-tpu    0.5344 +- 0.008  0.639484  \n",
       "beto-uncased-5000-tpu    0.5563 +- 0.009  0.640264  \n",
       "beto-uncased-15000       0.5571 +- 0.003  0.647335  \n",
       "beto-uncased-15000-last  0.5454 +- 0.005  0.637237  \n",
       "beto-cased-15000         0.5338 +- 0.003  0.639121  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-cased\",\n",
    "    \"beto-uncased\",\n",
    "    \"beto-ft-1000\",\n",
    "    \"beto-ft-2000\",\n",
    "    \"beto-uncased-1000\",\n",
    "    \"beto-uncased-2000\",\n",
    "    \"beto-uncased-5000\",\n",
    "    \"beto-uncased-5000-grito\",\n",
    "    \"beto-uncased-4000-tpu\",\n",
    "    \"beto-uncased-5000-tpu\",\n",
    "    \"beto-uncased-15000\",\n",
    "    \"beto-uncased-15000-last\",\n",
    "    \"beto-cased-15000\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate hateful_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c]\n",
    "\n",
    "df.loc[order, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"last\" es usando los mismos par√°metros que en el paper de finetuning\n",
    "\n",
    "No parecen ser los mejores!\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92ccad9e1098506b33031fe57a9203f449ec99e8a14bd2407df502eace4d0d50"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('finetune-vs-scratch-gHiQbun3-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
